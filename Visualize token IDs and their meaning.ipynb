{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPCHx6+K0SdG2Csbnvct9Nc"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"NZfvDzTFj8_F"},"outputs":[],"source":["from transformers import AutoTokenizer\n","\n","# Load a pretrained tokenizer\n","tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n","\n","# Texto más complejo\n","texto = \"`]~@ker9Mfi  la inteligencia artificial está haciendo t143%&%sr7_gejkokaniws el mundo laboral más desafiante\"\n","\n","# Tokenize the text\n","tokens = tokenizer.tokenize(texto)\n","token_ids = tokenizer.convert_tokens_to_ids(tokens)\n","\n","for token, token_id in zip(tokens, token_ids):\n","  print(f\"Token: {token:<20} ID: {token_id}\")"]}]}